{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://openenergy-platform.org/static/OEP_logo_2_no_text.svg\" alt=\"OpenEnergy Platform\" height=\"100\" width=\"100\"  align=\"left\"/>\n",
    "\n",
    "# OpenEnergyPlatform\n",
    "<br><br>\n",
    "\n",
    "## Usage of OpenEnergyPlatform oem2orm tool (using the oedialect)\n",
    "Repository: https://github.com/openego/oedialect <br>\n",
    "Documentation: http://oep-data-interface.readthedocs.io/en/latest/api/how_to.html\n",
    "\n",
    "Please report bugs and improvements here: https://github.com/OpenEnergyPlatform/oedialect/issues <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__copyright__ = \"Reiner Lemoine Institut\"\n",
    "__license__   = \"GNU Affero General Public License Version 3 (AGPL-3.0)\"\n",
    "__url__       = \"https://github.com/openego/data_processing/blob/master/LICENSE\"\n",
    "__author__    = \"jh-RLI, christian-rli\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: Creating sql tables, reading spatial-data, uploading to the oedb\n",
    "\n",
    "Takeaways:\n",
    "- How to create a table on the OEP from a oemetadata file\n",
    "- How to read sptial data (from .gkpg files) in python\n",
    "- How to upload this data to the OEP using the OEP-API and the oedialect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "First we set up the environment with all dependencies and provide the credentials to connect to the OEP. Then we setup our sql tables, we will do this using the oemetadata (oem) format in v1.4.0. The metadata strings should be reviewed first in order to avoid unsupported datatypes or other inconsistencies inside the string. If we use our own oem data this can lead to errors in the next steps. We use the oem2orm package to create sqlalchemy tables that are derived from the oemetadata files and then create the tables on the oep using the oep API (sqlachemy with oedialect). After that you should always check if the tables exist and are created properly. If this looks fine we can proceed to the next step and import our spatial data into a geopandas dataframe in python and then upload the data using the oedialect again. Geopandas provides all i/o functionality to do so. In this tutorial we focus on reading spatial-data from .gpkg files. \n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to be signed up to the [OEP](https://openenergy-platform.org/user/register) to access your username and API Token.\n",
    "\n",
    "To run this Jupyter Notebook you need to create an execution environment that contains all packages listed in the [requirements.txt](https://github.com/OpenEnergyPlatform/data-preprocessing/blob/feature/oep-upload-oem2orm/data-import/oep-upload/tutorials/requirements.txt) file. Keep in mind that you have to select this environment as kernel (maybe add [new kernel](https://ipython.readthedocs.io/en/stable/install/kernel_install.html)) in jupyter notebook.\n",
    "\n",
    "As described in the oem2orm [usage](https://github.com/OpenEnergyPlatform/data-preprocessing/blob/feature/oep-upload-oem2orm/data-import/oep-upload/README.md) details, it's best practice to clone this [GitHub](https://github.com/OpenEnergyPlatform/data-preprocessing) repository, as we only want to upload data that has been properly reviewed. The reviewed data can be found in the  If you want, you can still use your own data with this example, but be sure to delete your tables afterwards. The oem2orm tool also requires the use of [Open Energy Metadata (oem)](https://github.com/OpenEnergyPlatform/metadata/blob/develop/metadata/v140/template.json)in v1.4.0 or lower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import getpass\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import oedialect\n",
    "from oem2orm import oep_oedialect_oem2orm as oem2orm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to OEP\n",
    "\n",
    "If we want to upload data to the OEP we first need to connect to it, using our OEP user name and token.\n",
    "\n",
    "Note: You can view your token on your OEP profile page after logging in. \n",
    "\n",
    "The setup_db_connection function will promt for the user credentials and returns the DB nametuple which \n",
    "is used for all database interactions. DB contains the sqlachemy engine and metadata object. We don't need \n",
    "to pass parameters to the function, because we use the OEP in this example, which is the default database \n",
    "for oem2orm functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = oem2orm.setup_db_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating sql tables from oemetadata\n",
    "\n",
    "The oemetadata format is a json file format which is required for all data which should be uploaded to the oep. An advantage is that the data model with the used data types is included. So it is possible to derive sqlalchemy tables from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide an oemetadata file / Data Input\n",
    "\n",
    "In order to create the table we need to tell python where to find our oemetadata file first. To do this we place the oem file in v1.4.0 in the folder \"upload-example-metadata\" in the current directory (Path of this jupyter notebbok) or provide a path to our oemetadata folder. oem2orm is able to process all files that are located in a folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_folder = oem2orm.select_oem_dir(oem_folder_name=\"oem-upload-example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a Table\n",
    "\n",
    "The collect_tables_function collects all metadata files in a folder and retrives the SQLAlchemy ORM objects and returns them.\n",
    "The Tables are ordered by forigen key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_orm = oem2orm.collect_ordered_tables_from_oem(metadata_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the new Table\n",
    "\n",
    "Now we can use the function create_tables() from oem2orm to create all of our Table objects we just created in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oem2orm.create_tables(db, ordered_orm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Delete SQL tables \n",
    "\n",
    "If you dont want to upload data in the next step then you should delete you tables from the Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oem2orm.delete_tables(db, ordered_orm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading spatial-data and 3. uploading it to the oedb\n",
    "\n",
    "Geopandas offers functionality for spatial data. The read_file() function can read data from several sources \n",
    "e.g. .gkpg, .geojson, ... the function is also able to import the data by using an url that provides the data.\n",
    "\n",
    "FYI see: https://geopandas.org/io.html\n",
    "\n",
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gdf = gpd.read_file('../data/TemplateData.csv', layer='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first three lines of our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert (upload) data into Table\n",
    " \n",
    "Uploading the information from our DataFrame is now done with a single command. Uploading data in this way will always delete the content of the table and refill it with new values every time. If you change 'replace' to 'append', the data entries will be added to the preexisting ones. (Connecting and uploading may take a minute.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "try: \n",
    "    example_df.to_sql(table_name, conn, schema_name, if_exists='replace')\n",
    "    print('Inserted to ' + table_name)\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    raise\n",
    "    print('Insert incomplete!')\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also insert data manually into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "try:\n",
    "    insert_statement = ExampleTable.insert().values(\n",
    "        [\n",
    "            dict(variable='fairy dust', unit='t', year=2020, value=200),\n",
    "            dict(variable='mana', unit='kg', year=1999, value=120),\n",
    "            dict(variable='the force', unit='l', year=1998, value=1100)\n",
    "        ]\n",
    "    )\n",
    "    session.execute(insert_statement)\n",
    "    session.commit()\n",
    "    print('Insert successful!')\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    raise\n",
    "    print('Insert incomplete!')\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Retriving data, verify that the tables exist and data is uploaded successfully\n",
    "\n",
    "### Select from Table\n",
    "\n",
    "Now  we can query our table to see if the data arrived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "print(session.query(ExampleTable).all())\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Query Result in DataFrame\n",
    "We can write the results of the query back into a DataFrame, where it's easier to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "df = pd.DataFrame(session.query(ExampleTable).all())\n",
    "session.close()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show oedialect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oep-upload",
   "language": "python",
   "name": "oep-upload"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
