{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://openenergy-platform.org/static/OEP_logo_2_no_text.svg\" alt=\"OpenEnergy Platform\" height=\"100\" width=\"100\"  align=\"left\"/>\n",
    "\n",
    "# OpenEnergyPlatform\n",
    "<br><br>\n",
    "\n",
    "## Usage of OpenEnergyPlatform API-Dialect (oedialect)\n",
    "Repository: https://github.com/openego/oedialect <br>\n",
    "Documentation: http://oep-data-interface.readthedocs.io/en/latest/api/how_to.html\n",
    "\n",
    "Please report bugs and improvements here: https://github.com/OpenEnergyPlatform/oedialect/issues <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__copyright__ = \"Reiner Lemoine Institut\"\n",
    "__license__   = \"GNU Affero General Public License Version 3 (AGPL-3.0)\"\n",
    "__url__       = \"https://github.com/openego/data_processing/blob/master/LICENSE\"\n",
    "__author__    = \"jh-RLI, christian-rli\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: Creating sql tables, reading spatial-data, uploading to the oedb\n",
    "\n",
    "Takeaways:\n",
    "- How to create a table on the OEP from a oemetadata file\n",
    "- How to read sptial data (from .gkpg files) in python\n",
    "- How to upload this data to the OEP using the OEP-API and the oedialect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "First we set up the environment with all dependencys (see requirements.txt) and provide the credentials to connect to the OEP. Then we setup our sql tables, we will do this using the oemetadata format in v1.4.0. The metadata strings should be reviewed first in order to avoid unsupported datatypes or other inconsistencies inside the string. This can lead to errors in the next steps. We use the script to create sqlalchemy tables that are derived from the oemetadata and then create the tables on the oep using sqlachemy with oedialect. After that you should always check if the tables exist and are created properly. If this looks fine we can proceed to the next step and import our spatial data into a geopandas dataframe in python and then upload the data using the oedialect again. Geopandas provides all i/o functionality to do so. \n",
    "\n",
    "In this tutorial we focus on reading spatial-data from .gpkg files. Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import getpass\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import oedialect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to OEP\n",
    "\n",
    "If we want to upload data to the OEP we first need to connect to it, using our OEP user name and token. \n",
    "Note: You ca view your token on your OEP profile page after logging in.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White spaces in the username are fine!\n",
    "user = input('Enter OEP-username:')\n",
    "token = getpass.getpass('Token:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create an sql-alchemy-engine. The engine is what 'speaks' oedialect to the data base api. We need to tell it where the data base is and pass our credentials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Engine:\n",
    "OEP_URL = 'openenergy-platform.org' #'193.175.187.164' #'oep.iks.cs.ovgu.de'\n",
    "OED_STRING = f'postgresql+oedialect://{user}:{token}@{OEP_URL}'\n",
    "\n",
    "engine = sa.create_engine(OED_STRING)\n",
    "metadata = sa.MetaData(bind=engine)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating sql tables from oemetadata\n",
    "\n",
    "The oemetadata format is a json file-format that has to be created for all data to be uploaded to the oep. One advantage is that the data model with the used data types is included. So it is possible to derive sql tables from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide an oemetadata file\n",
    "\n",
    "In order to create the table first we need to tell python where to find our oemetadata file. To do this we place the reviewd file in the folder \"upload-metadata\" in the current directoy or provide a path to our oemetadata folder. The skript is able to process all files that are located in a folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a Table\n",
    "\n",
    "We need to tell the data base what columns and datatypes we are about to upload. In our case we have four columns, two of which are text, one is integer and the last is float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'example_dialect_table'\n",
    "schema_name = 'sandbox'\n",
    "\n",
    "ExampleTable = sa.Table(\n",
    "    table_name,\n",
    "    metadata,\n",
    "    sa.Column('variable', sa.VARCHAR(50)),\n",
    "    sa.Column('unit', sa.VARCHAR(50)),\n",
    "    sa.Column('year', sa.INTEGER),\n",
    "    sa.Column('value', sa.FLOAT(50)),\n",
    "    schema=schema_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the new Table\n",
    "\n",
    "Now we tell our engine to connect to the data base and create the defined table within the chosen schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = engine.connect()\n",
    "print('Connection established')\n",
    "if not engine.dialect.has_table(conn, table_name, schema_name):\n",
    "    ExampleTable.create()\n",
    "    print('Created table')\n",
    "else:\n",
    "    print('Table already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading spatial-data and 3. uploading it to the oedb\n",
    "\n",
    "Geopandas offers functionality for spatial data. The read_file() function can read data from several sources \n",
    "e.g. .gkpg, .geojson, ... the function is also able to import the data by using an url that provides the data.\n",
    "\n",
    "FYI see: https://geopandas.org/io.html\n",
    "\n",
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not UnparsedPath",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bd22ac1d73f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexample_gdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/TemplateData.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\oep-upload\\lib\\site-packages\\geopandas\\io\\file.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\oep-upload\\lib\\site-packages\\fiona\\env.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\oep-upload\\lib\\site-packages\\fiona\\__init__.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[1;32m--> 254\u001b[1;33m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\oep-upload\\lib\\site-packages\\fiona\\collection.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\oep-upload\\lib\\ntpath.py\u001b[0m in \u001b[0;36msplitext\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgenericpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_splitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb'\\\\'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb'/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mb'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not UnparsedPath"
     ]
    }
   ],
   "source": [
    "example_gdf = gpd.read_file('../data/TemplateData.csv', layer='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first three lines of our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert (upload) data into Table\n",
    " \n",
    "Uploading the information from our DataFrame is now done with a single command. Uploading data in this way will always delete the content of the table and refill it with new values every time. If you change 'replace' to 'append', the data entries will be added to the preexisting ones. (Connecting and uploading may take a minute.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "try: \n",
    "    example_df.to_sql(table_name, conn, schema_name, if_exists='replace')\n",
    "    print('Inserted to ' + table_name)\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    raise\n",
    "    print('Insert incomplete!')\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also insert data manually into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "try:\n",
    "    insert_statement = ExampleTable.insert().values(\n",
    "        [\n",
    "            dict(variable='fairy dust', unit='t', year=2020, value=200),\n",
    "            dict(variable='mana', unit='kg', year=1999, value=120),\n",
    "            dict(variable='the force', unit='l', year=1998, value=1100)\n",
    "        ]\n",
    "    )\n",
    "    session.execute(insert_statement)\n",
    "    session.commit()\n",
    "    print('Insert successful!')\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    raise\n",
    "    print('Insert incomplete!')\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Retriving data, verify that the tables exist and data is uploaded successfully\n",
    "\n",
    "### Select from Table\n",
    "\n",
    "Now  we can query our table to see if the data arrived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "print(session.query(ExampleTable).all())\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Query Result in DataFrame\n",
    "We can write the results of the query back into a DataFrame, where it's easier to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "df = pd.DataFrame(session.query(ExampleTable).all())\n",
    "session.close()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show oedialect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oep-upload",
   "language": "python",
   "name": "oep-upload"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
